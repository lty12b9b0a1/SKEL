{
    "1": "class_var.func = func;\nreturn null;\n",
    "2": "\n",
    "3": "var obj = args[0];\n    if (!obj.__cache) {\n        obj.__cache = new Map();\n    }\n    var cache = obj.__cache;\n    // var key = class_var.func.name;\n    if (!cache.has(class_var)) {\n        cache.set(class_var, class_var.func(...args))\n    }\n    return cache.get(class_var);\n",
    "4": "\n",
    "5": "\n",
    "6": "    if (qword === 0) {\n        return new Date(-8640000000000000);\n    }\n    try {\n        return new Date((qword * 1e-7 - 11644473600) * 1000);\n    } catch (e) {\n        return new Date(-8640000000000000);\n    }\n",
    "7": "\n",
    "8": "\n",
    "9": "\n",
    "10": "\n",
    "11": "\n",
    "12": "\n",
    "13": "\n",
    "14": "\n",
    "15": "\n",
    "16": "class_var._buf = buf;\nclass_var._offset = offset;\nclass_var._implicit_offset = 0;\n",
    "17": "\n",
    "18": "\n",
    "19": "var f = class_var[\"unpack_\" + type];\n    return f(offset);\n",
    "20": "var f = class_var[\"unpack_\" + type];\n    return f(offset, length);\n",
    "21": "if (offset === null) {\n    offset = class_var._implicit_offset;\n}\nif (length === null) {\n    class_var[name] = no_length_handler;\n} else {\n    class_var[name] = explicit_length_handler;\n}\nclass_var[\"_off_\" + name] = offset;\nif (type === \"byte\" || type === \"int8\") {\n    class_var._implicit_offset = offset + 1;\n} else if (type === \"word\" || type === \"word_be\" || type === \"int16\") {\n    class_var._implicit_offset = offset + 2;\n} else if (type === \"dword\" || type === \"dword_be\" || type === \"int32\" || type === \"float\") {\n    class_var._implicit_offset = offset + 4;\n} else if (type === \"qword\" || type === \"int64\" || type === \"double\" || type === \"filetime\" || type === \"systemtime\") {\n    class_var._implicit_offset = offset + 8;\n} else if (type === \"guid\") {\n    class_var._implicit_offset = offset + 16;\n} else if (type === \"binary\") {\n    class_var._implicit_offset = offset + length;\n} else if (type === \"string\" && length !== null) {\n    class_var._implicit_offset = offset + length;\n} else if (type === \"wstring\" && length !== null) {\n    class_var._implicit_offset = offset + (2 * length);\n} else if (type.includes(\"string\") && length === null) {\n    throw new Error(\"Implicit offset not supported for dynamic length strings\");\n} else {\n    throw new Error(\"Implicit offset not supported for type: \" + type);\n}\n",
    "22": "return class_var._implicit_offset;\n",
    "23": "var o = class_var._offset + offset;\ntry {\n    var dataView = new DataView(class_var._buf.buffer);\n    return dataView.getUint8(o);\n} catch (error) {\n    throw new OverrunBufferException(o, class_var._buf.length);\n}\n",
    "24": "\n",
    "25": "var o = class_var._offset + offset;\n    try {\n        var dataView = new DataView(class_var._buf.buffer);\n        return dataView.getUint16(o, true); // true for little-endian\n    } catch (error) {\n        throw new Error(`OverrunBufferException: position ${o}, buffer length ${class_var._buf.byteLength}`);\n    }\n",
    "26": "var o = class_var._offset + offset;\ntry {\n    var dataView = new DataView(class_var._buf.buffer);\n    return dataView.getUint16(o, false); // false for big-endian\n} catch (error) {\n    throw new OverrunBufferException(o, class_var._buf.length);\n}\n",
    "27": "\n",
    "28": "\n",
    "29": "var o = class_var._offset + offset;\ntry {\n    var dataView = new DataView(class_var._buf.buffer);\n    return dataView.getUint32(o, true); // true for little-endian\n} catch (error) {\n    throw new OverrunBufferException(o, class_var._buf.length);\n}\n",
    "30": "var o = class_var._offset + offset;\ntry {\n    var dataView = new DataView(class_var._buf.buffer);\n    return dataView.getUint32(o, false); // false for big-endian\n} catch (error) {\n    throw new OverrunBufferException(o, class_var._buf.length);\n}\n",
    "31": "var o = class_var._offset + offset;\ntry {\n    var dataView = new DataView(class_var._buf.buffer);\n    return dataView.getInt32(o, true); // true for little-endian\n} catch (error) {\n    throw new OverrunBufferException(o, class_var._buf.length);\n}\n",
    "32": "var o = class_var._offset + offset;\ntry {\n    var dataView = new DataView(class_var._buf.buffer, o, 8); // Specify the offset and length directly in DataView\n    return dataView.getUint32(0, true) + dataView.getUint32(4, true) * 0x100000000; // true for little-endian\n} catch (error) {\n    throw new Error(`OverrunBufferException at offset ${o} with buffer length ${class_var._buf.byteLength}`);\n}\n",
    "33": "\n",
    "34": "\n",
    "35": "\n",
    "36": "if (!length) {\n    return new Uint8Array().buffer;\n}\nvar o = class_var._offset + offset;\ntry {\n    var result = new Uint8Array(class_var._buf.slice(o, o + length));\n    return Buffer.from(result);\n} catch (error) {\n    throw new OverrunBufferException(o, class_var._buf.byteLength);\n}\n",
    "37": "return String.fromCharCode.apply(null, class_var.unpack_binary(offset, length));\n",
    "38": "var start = class_var._offset + offset;\nvar end = class_var._offset + offset + 2 * length;\ntry {\n    return new TextDecoder(\"utf-16\").decode(class_var._buf.slice(start, end));\n} catch (e) {\n    return new TextDecoder(\"utf-16\").decode(class_var._buf.slice(start, end));\n}\n",
    "39": "\n",
    "40": "return parse_filetime(class_var.unpack_qword(offset));\n",
    "41": "\n",
    "42": "var o = class_var._offset + offset;\nvar _bin;\ntry {\n    _bin = class_var._buf.slice(o, o + 16);\n} catch (e) {\n    if (e instanceof RangeError) {\n        throw new OverrunBufferException(o, class_var._buf.length);\n    }\n}\nvar h = [];\nfor (var i = 0; i < _bin.length; i++) {\n    h.push(_bin[i]);\n}\nreturn `${h[3].toString(16).padStart(2, '0')}${h[2].toString(16).padStart(2, '0')}${h[1].toString(16).padStart(2, '0')}${h[0].toString(16).padStart(2, '0')}-${h[5].toString(16).padStart(2, '0')}${h[4].toString(16).padStart(2, '0')}-${h[7].toString(16).padStart(2, '0')}${h[6].toString(16).padStart(2, '0')}-${h[8].toString(16).padStart(2, '0')}${h[9].toString(16).padStart(2, '0')}-${h[10].toString(16).padStart(2, '0')}${h[11].toString(16).padStart(2, '0')}${h[12].toString(16).padStart(2, '0')}${h[13].toString(16).padStart(2, '0')}${h[14].toString(16).padStart(2, '0')}${h[15].toString(16).padStart(2, '0')}`;\n",
    "43": "\n",
    "44": "return class_var._offset;\n",
    "45": "\n",
    "46": "\n",
    "47": "class_var._chunk = chunk;\nclass_var._parent = parent;\nreturn null;\n",
    "48": "\n",
    "49": "\n",
    "50": "\n",
    "51": "\n",
    "52": "var ret = [];\nvar ofs = class_var.tag_length();\nvar gen;\nif (max_children !== null) {\n    gen = Array.from({length: max_children}, (_, i) => i);\n} else {\n    gen = tool_functions.user_infinite_counter();\n}\nfor (var _ of gen) {\n    var token = class_var.unpack_byte(ofs) & 0x0F;\n    try {\n        var HandlerNodeClass = node_dispatch_table[token];\n        var child = new HandlerNodeClass(class_var._buf, class_var.offset() + ofs, class_var._chunk, class_var);\n    } catch (error) {\n        throw new Error(`Unexpected token ${token.toString(16).toUpperCase().padStart(2, '0')} at ${class_var.absolute_offset(0x0) + ofs}`);\n    }\n    ret.push(child);\n    ofs += child.length();\n    if (end_tokens.includes(token)) {\n        break;\n    }\n    if (child.find_end_of_stream()) {\n        break;\n    }\n}\nreturn ret;\n",
    "53": "return class_var._children(null, [0]);\n",
    "54": "var ret = class_var.tag_length();\n    for (var child of class_var.children()) {\n        ret += child.length();\n    }\n    return ret;\n",
    "55": "        for (var child of class_var.children()) {\n            if (user_check_type(child, EndOfStreamNode)) {\n                return child;\n            }\n            var ret = child.find_end_of_stream();\n            if (ret) {\n                return ret;\n            }\n        }\n        return null;\n",
    "56": "class_var.declare_field(\"dword\", \"next_offset\", 0x0, null);\nclass_var.declare_field(\"word\", \"hash\", null, null);\nclass_var.declare_field(\"word\", \"string_length\", null, null);\nclass_var.declare_field(\"wstring\", \"string\", null, class_var.string_length());\n",
    "57": "\n",
    "58": "\n",
    "59": "\n",
    "60": "try {\n    return (class_var.string_length() * 2) + 8;\n} catch (error) {\n    no_length_handler();\n}\n",
    "61": "return class_var.tag_length() + 2;\n",
    "62": "class_var.declare_field(\"dword\", \"next_offset\", 0x0, null);\nclass_var.declare_field(\"dword\", \"template_id\", null, null);\nclass_var.declare_field(\"guid\", \"guid\", 0x04, null);\nclass_var.declare_field(\"dword\", \"data_length\", null, null);\n",
    "63": "\n",
    "64": "\n",
    "65": "return 0x18;\n",
    "66": "return class_var.tag_length() + class_var.data_length();\n",
    "67": "return null;\n",
    "68": "\n",
    "69": "\n",
    "70": "\n",
    "71": "\n",
    "72": "return 1;\n",
    "73": "return [];\n",
    "74": "class_var.declare_field(\"byte\", \"token\", 0x0, null);\nclass_var.declare_field(\"word\", \"unknown0\", null, null);\n// TODO(wb): use this size() field.\nclass_var.declare_field(\"dword\", \"size\", null, null);\nclass_var.declare_field(\"dword\", \"string_offset\", null, null);\nclass_var._tag_length = 11;\nclass_var._element_type = 0;\nif (class_var.flags() & 0x04) {\n    class_var._tag_length += 4;\n}\nif (class_var.string_offset() > class_var.offset() - class_var._chunk._offset) {\n    var new_string = class_var._chunk.add_string(class_var.string_offset(), class_var);\n    class_var._tag_length += new_string.length();\n}\n",
    "75": "\n",
    "76": "\n",
    "77": "\n",
    "78": "return class_var.token() >> 4;\n",
    "79": "return class_var._chunk.strings()[class_var.string_offset()].string();\n",
    "80": "return class_var._tag_length;\n",
    "81": "\n",
    "82": "return class_var._children(null, [SYSTEM_TOKENS.CloseElementToken, SYSTEM_TOKENS.CloseEmptyElementToken]);\n",
    "83": "class_var.declare_field(\"byte\", \"token\", 0x0, null);\n",
    "84": "\n",
    "85": "\n",
    "86": "\n",
    "87": "\n",
    "88": "return 1;\n",
    "89": "return [];\n",
    "90": "\n",
    "91": "class_var.declare_field(\"byte\", \"token\", 0x0, null);\n",
    "92": "\n",
    "93": "\n",
    "94": "\n",
    "95": "\n",
    "96": "return 1;\n",
    "97": "return [];\n",
    "98": "class_var.declare_field(\"byte\", \"token\", 0x0, null);\n",
    "99": "\n",
    "100": "\n",
    "101": "\n",
    "102": "\n",
    "103": "return 1;\n",
    "104": "return [];\n",
    "105": "\n",
    "106": "var types = {\n    [NODE_TYPES.NULL]: NullTypeNode,\n    [NODE_TYPES.WSTRING]: WstringTypeNode,\n    [NODE_TYPES.STRING]: StringTypeNode,\n    [NODE_TYPES.SIGNED_BYTE]: SignedByteTypeNode,\n    [NODE_TYPES.UNSIGNED_BYTE]: UnsignedByteTypeNode,\n    [NODE_TYPES.SIGNED_WORD]: SignedWordTypeNode,\n    [NODE_TYPES.UNSIGNED_WORD]: UnsignedWordTypeNode,\n    [NODE_TYPES.SIGNED_DWORD]: SignedDwordTypeNode,\n    [NODE_TYPES.UNSIGNED_DWORD]: UnsignedDwordTypeNode,\n    [NODE_TYPES.SIGNED_QWORD]: SignedQwordTypeNode,\n    [NODE_TYPES.UNSIGNED_QWORD]: UnsignedQwordTypeNode,\n    [NODE_TYPES.FLOAT]: FloatTypeNode,\n    [NODE_TYPES.DOUBLE]: DoubleTypeNode,\n    [NODE_TYPES.BOOLEAN]: BooleanTypeNode,\n    [NODE_TYPES.BINARY]: BinaryTypeNode,\n    [NODE_TYPES.GUID]: GuidTypeNode,\n    [NODE_TYPES.SIZE]: SizeTypeNode,\n    [NODE_TYPES.FILETIME]: FiletimeTypeNode,\n    [NODE_TYPES.SYSTEMTIME]: SystemtimeTypeNode,\n    [NODE_TYPES.SID]: SIDTypeNode,\n    [NODE_TYPES.HEX32]: Hex32TypeNode,\n    [NODE_TYPES.HEX64]: Hex64TypeNode,\n    [NODE_TYPES.BXML]: BXmlTypeNode,\n    [NODE_TYPES.WSTRINGARRAY]: WstringArrayTypeNode,\n};\n\nvar TypeClass;\nif (types[type_] === undefined) {\n    throw new Error(\"Type \" + type_ + \" not implemented\");\n} else {\n    TypeClass = types[type_];\n}\nreturn new TypeClass(buf, offset, chunk, parent, length);\n",
    "107": "class_var.declare_field(\"byte\", \"token\", 0, null);\nclass_var.declare_field(\"byte\", \"type\", null, null);\n",
    "108": "\n",
    "109": "\n",
    "110": "\n",
    "111": "\n",
    "112": "return 2;\n",
    "113": "var child = get_variant_value(class_var._buf, class_var.offset() + class_var.tag_length(), class_var._chunk, class_var, class_var.type(), null);\nreturn [child];\n",
    "114": "\n",
    "115": "class_var.declare_field(\"byte\", \"token\", 0x0, null);\nclass_var.declare_field(\"dword\", \"string_offset\", null, null);\nclass_var._name_string_length = 0;\nif (class_var.string_offset() > class_var.offset() - class_var._chunk._offset) {\n    var new_string = class_var._chunk.add_string(class_var.string_offset(), class_var);\n    class_var._name_string_length += new_string.length();\n}\n",
    "116": "\n",
    "117": "\n",
    "118": "\n",
    "119": "return class_var._chunk.strings()[class_var.string_offset()];\n",
    "120": "return class_var.children()[0];\n",
    "121": "return 5 + class_var._name_string_length;\n",
    "122": "\n",
    "123": "return class_var._children(1, [0x00]);\n",
    "124": "\n",
    "125": "\n",
    "126": "\n",
    "127": "\n",
    "128": "\n",
    "129": "\n",
    "130": "\n",
    "131": "\n",
    "132": "\n",
    "133": "\n",
    "134": "\n",
    "135": "\n",
    "136": "\n",
    "137": "\n",
    "138": "\n",
    "139": "\n",
    "140": "\n",
    "141": "\n",
    "142": "\n",
    "143": "\n",
    "144": "\n",
    "145": "\n",
    "146": "\n",
    "147": "\n",
    "148": "\n",
    "149": "\n",
    "150": "\n",
    "151": "\n",
    "152": "\n",
    "153": "\n",
    "154": "\n",
    "155": "\n",
    "156": "\n",
    "157": "\n",
    "158": "\n",
    "159": "\n",
    "160": "class_var.declare_field(\"byte\", \"token\", 0x0, null);\nclass_var.declare_field(\"byte\", \"unknown0\", null, null);\nclass_var.declare_field(\"dword\", \"template_id\", null, null);\nclass_var.declare_field(\"dword\", \"template_offset\", null, null);\nclass_var._data_length = 0;\nif (class_var.is_resident_template()) {\n    var new_template = class_var._chunk.add_template(class_var.template_offset(), class_var);\n    class_var._data_length += new_template.length();\n}\n",
    "161": "\n",
    "162": "\n",
    "163": "\n",
    "164": "return class_var.template_offset() > class_var.offset() - class_var._chunk._offset;\n",
    "165": "return 10;\n",
    "166": "return class_var.tag_length() + class_var._data_length;\n",
    "167": "return class_var._chunk.templates()[class_var.template_offset()];\n",
    "168": "return [];\n",
    "169": "return class_var.template().find_end_of_stream();\n",
    "170": "class_var.declare_field(\"byte\", \"token\", 0x0, null);\nclass_var.declare_field(\"word\", \"index\", null, null);\nclass_var.declare_field(\"byte\", \"type\", null, null);\n",
    "171": "\n",
    "172": "\n",
    "173": "\n",
    "174": "return 0x4;\n",
    "175": "return class_var.tag_length();\n",
    "176": "return [];\n",
    "177": "\n",
    "178": "class_var.declare_field(\"byte\", \"token\", 0x0, null);\nclass_var.declare_field(\"word\", \"index\", null, null);\nclass_var.declare_field(\"byte\", \"type\", null, null);\n",
    "179": "\n",
    "180": "\n",
    "181": "\n",
    "182": "\n",
    "183": "return 0x4;\n",
    "184": "return class_var.tag_length();\n",
    "185": "return [];\n",
    "186": "\n",
    "187": "class_var.declare_field(\"byte\", \"token\", 0, null);\nclass_var.declare_field(\"byte\", \"unknown0\", null, null);\nclass_var.declare_field(\"word\", \"unknown1\", null, null);\n",
    "188": "\n",
    "189": "\n",
    "190": "\n",
    "191": "\n",
    "192": "return 4;\n",
    "193": "return class_var.tag_length() + 0;\n",
    "194": "return [];\n",
    "195": "return null;\n",
    "196": "\n",
    "197": "\n",
    "198": "return 0;\n",
    "199": "return class_var._children(null, [SYSTEM_TOKENS.EndOfStreamToken]);\n",
    "200": "var children_length = 0;\n    for (var child of class_var.children()) {\n        children_length += child.length();\n    }\n    return class_var.tag_length() + children_length;\n",
    "201": "var ofs = class_var.offset();\nif ((class_var.unpack_byte(0x0) & 0x0F) === 0xF) {\n    ofs += 4;\n}\nreturn new TemplateInstanceNode(class_var._buf, ofs, class_var._chunk, class_var);\n",
    "202": "var instance = class_var.template_instance();\nvar offset = class_var._chunk.offset() + instance.template_offset();\nvar node = new TemplateNode(class_var._buf, offset, class_var._chunk, instance);\nreturn node;\n",
    "203": "var sub_decl = [];\nvar sub_def = [];\nvar ofs = class_var.tag_and_children_length();\nvar sub_count = class_var.unpack_dword(ofs);\nofs += 4;\nfor (var _ = 0; _ < sub_count; _++) {\n    var size = class_var.unpack_word(ofs);\n    var type_ = class_var.unpack_byte(ofs + 0x2);\n    sub_decl.push([size, type_]);\n    ofs += 4;\n}\nfor (var index = 0; index < sub_decl.length; index++) {\n    var size = sub_decl[index][0];\n    var type_ = sub_decl[index][1];\n    var val = get_variant_value(class_var._buf, class_var.offset() + ofs, class_var._chunk, class_var, type_, size);\n    if (Math.abs(size - val.length()) > 4) {\n        throw new Error(\"Invalid substitution value size\");\n    }\n    sub_def.push(val);\n    ofs += size;\n}\nreturn sub_def;\n",
    "204": "\n",
    "205": "class_var._length = length;\nreturn null;\n",
    "206": "\n",
    "207": "\n",
    "208": "\n",
    "209": "return class_var.tag_length();\n",
    "210": "return [];\n",
    "211": "\n",
    "212": "class_var._offset = offset;\nclass_var._length = length;\n",
    "213": "\n",
    "214": "return \"\";\n",
    "215": "return class_var._length || 0;\n",
    "216": "\n",
    "217": "return [];\n",
    "218": "\n",
    "219": "if (class_var._length === null) {\n    class_var.declare_field(\"word\", \"string_length\", 0x0, null);\n    class_var.declare_field(\"wstring\", \"_string\", null, class_var.string_length());\n} else {\n    class_var.declare_field(\"wstring\", \"_string\", 0x0, Math.floor(class_var._length / 2));\n}\n",
    "220": "if (class_var._length === null) {\n    return 2 + (class_var.string_length() * 2);\n}\nreturn class_var._length;\n",
    "221": "return class_var._string().replace(/\\x00+$/, '');\n",
    "222": "\n",
    "223": "\n",
    "224": "\n",
    "225": "\n",
    "226": "\n",
    "227": "\n",
    "228": "class_var.declare_field(\"byte\", \"byte\", 0x0, null);\n",
    "229": "return 1;\n",
    "230": "return String(class_var.byte());\n",
    "231": "\n",
    "232": "\n",
    "233": "\n",
    "234": "class_var.declare_field(\"word\", \"word\", 0, null);\n",
    "235": "return 2;\n",
    "236": "return String(class_var.word());\n",
    "237": "\n",
    "238": "\n",
    "239": "\n",
    "240": "class_var.declare_field(\"dword\", \"dword\", 0, null);\n",
    "241": "return 4;\n",
    "242": "return String(class_var.dword());\n",
    "243": "\n",
    "244": "\n",
    "245": "\n",
    "246": "class_var.declare_field(\"qword\", \"qword\", 0, null);\n",
    "247": "return 8;\n",
    "248": "return String(class_var.qword());\n",
    "249": "\n",
    "250": "\n",
    "251": "\n",
    "252": "\n",
    "253": "\n",
    "254": "\n",
    "255": "class_var.declare_field(\"int32\", \"int32\", 0, null);\n",
    "256": "return 4;\n",
    "257": "if (class_var.int32() > 0) {\n    return \"True\";\n}\nreturn \"False\";\n",
    "258": "if (class_var._length === null) {\n    class_var.declare_field(\"dword\", \"size\", 0x0);\n    class_var.declare_field(\"binary\", \"binary\", {length: class_var.size()});\n} else {\n    class_var.declare_field(\"binary\", \"binary\", 0x0, class_var._length);\n}\n",
    "259": "if (class_var._length === null) {\n    return 4 + class_var.size();\n}\nreturn class_var._length;\n",
    "260": "return btoa(String.fromCharCode.apply(null, new Uint8Array(class_var.binary())));\n",
    "261": "class_var.declare_field(\"guid\", \"guid\", 0, null);\n",
    "262": "return 16;\n",
    "263": "return \"{\" + class_var.guid() + \"}\";\n",
    "264": "\n",
    "265": "\n",
    "266": "\n",
    "267": "class_var.declare_field(\"filetime\", \"filetime\", 0x0, null);\n",
    "268": "var t = class_var.filetime();\n    return \"time not supported\";\n",
    "269": "return 8;\n",
    "270": "\n",
    "271": "\n",
    "272": "\n",
    "273": "class_var.declare_field(\"byte\", \"version\", 0x0, null);\nclass_var.declare_field(\"byte\", \"num_elements\", null, null);\nclass_var.declare_field(\"dword_be\", \"id_high\", null, null);\nclass_var.declare_field(\"word_be\", \"id_low\", null, null);\n",
    "274": "        ret = [];\n        var tmp = class_var[\"num_elements\"]();\n        for (var i = 0; i < tmp; i++) {\n            ret.push(class_var[\"unpack_dword\"](class_var[\"current_field_offset\"]() + 4 * i));\n        }\n        return ret;\n",
    "275": "var ret = \"S-\" + class_var.version() + \"-\" + ((class_var.id_high() << 16) ^ class_var.id_low());\n        class_var.elements().forEach(function(elem) {\n            ret += \"-\" + elem;\n        });\n        return ret;\n",
    "276": "return 8 + 4 * class_var.num_elements();\n",
    "277": "return class_var.id();\n",
    "278": "class_var.declare_field(\"binary\", \"hex\", 0x0, 0x4);\n",
    "279": "return 4;\n",
    "280": "var ret = \"0x\";\n    var b = Buffer.from(class_var.hex(), 'hex');\n    for (var i = b.length - 1; i >= 0; i--) {\n        ret += (\"0\" + b[i].toString(16)).slice(-2);\n    }\n    return ret;\n",
    "281": "class_var.declare_field(\"binary\", \"hex\", 0x0, 0x8);\n",
    "282": "return 8;\n",
    "283": "        ret = \"0x\";\n        b = Array.from(class_var.hex()).reverse();\n        for (var i = 0; i < b.length; i++) {\n            ret += b[i].toString(16).padStart(2, '0');\n        }\n        _return_value = ret;\n        return _return_value;\n",
    "284": "class_var._root = new RootNode(buf, offset, chunk, class_var);\n",
    "285": "return class_var._length || class_var._root.length();\n",
    "286": "\n",
    "287": "return class_var._root;\n",
    "288": "if (class_var._length === null) {\n    class_var.declare_field(\"word\", \"binary_length\", 0x0);\n    class_var.declare_field(\"binary\", \"binary\", {length: class_var.binary_length()});\n} else {\n    class_var.declare_field(\"binary\", \"binary\", 0x0, class_var._length);\n}\n",
    "289": "if (class_var._length === null) {\n    return 2 + class_var.binary_length();\n}\nreturn class_var._length;\n",
    "290": "        binary = class_var[\"binary\"]();\n        acc = [];\n        let binaryString = Array.from(binary, byte => String.fromCharCode(byte)).join(\"\");\n        while (binaryString.length > 0) {\n            var match = binaryString.match(/(?:[^\\x00].)+/);\n            if (match) {\n                var frag = match[0];\n                acc.push(\"<string>\");\n                acc.push(new TextDecoder(\"utf-16\").decode(new Uint8Array(frag.split(\"\").map(ch => ch.charCodeAt(0)))));\n                acc.push(\"</string>\\n\");\n                binaryString = binaryString.slice(frag.length + 2);\n                if (binaryString.length === 0) {\n                    break;\n                }\n            }\n            frag = binaryString.match(/(\\x00*)/)[0];\n            if (frag.length % 2 === 0) {\n                for (var _ = 0; _ < frag.length / 2; _++) {\n                    acc.push(\"<string></string>\\n\");\n                }\n            } else {\n                throw new Error(\"Error parsing uneven substring of NULLs\");\n            }\n            binaryString = binaryString.slice(frag.length);\n        }\n        var _return_value = acc.join(\"\");\n    \n        return _return_value;\n",
    "291": "\n",
    "292": "\n",
    "293": "var RESTRICTED_CHARS = /[\\x01-\\x08\\x0B\\x0C\\x0E-\\x1F\\x7F-\\x84\\x86-\\x9F]/g;\n    var esc = s.replace(/&/g, '&amp;').replace(/</g, '&lt;').replace(/>/g, '&gt;').replace(/\"/g, '&quot;').replace(/'/g, '&#x27;');\n    esc = esc.replace(/[\\u0080-\\uFFFF]/g, function(m) {\n        return '&#' + m.charCodeAt(0) + ';';\n    });\n    esc = esc.replace(RESTRICTED_CHARS, '');\n    return esc;\n",
    "294": "var NAME_PATTERN = tool_functions.NAME_PATTERN;\n    if (!NAME_PATTERN.test(s)) {\n        throw new Error(\"invalid xml name: \" + s);\n    }\n    return s;\n",
    "295": "        if (user_check_type(node, EndOfStreamNode)) {\n            // intended\n        } else if (user_check_type(node, OpenStartElementNode)) {\n            acc.push(\"<\");\n            acc.push(node.tag_name());\n            node.children().forEach(function(child) {\n                if (user_check_type(child, AttributeNode)) {\n                    acc.push(\" \");\n                    acc.push(validate_name(child.attribute_name().string()));\n                    acc.push('=\"');\n                    // TODO: should use xml.sax.saxutils.quoteattr here\n                    // but to do so, we'd need to ensure we're not double-quoting this value.\n                    rec(child.attribute_value(), acc);\n                    acc.push('\"');\n                }\n            });\n            acc.push(\">\");\n            node.children().forEach(function(child) {\n                rec(child, acc);\n            });\n            acc.push(\"</\");\n            acc.push(validate_name(node.tag_name()));\n            acc.push(\">\\n\");\n        } else if (user_check_type(node, CloseStartElementNode)) {\n            // intended\n        } else if (user_check_type(node, CloseEmptyElementNode)) {\n            // intended\n        } else if (user_check_type(node, CloseElementNode)) {\n            // intended\n        } else if (user_check_type(node, ValueNode)) {\n            acc.push(escape_value(node.children()[0].string()));\n        } else if (user_check_type(node, AttributeNode)) {\n            // intended\n        } else if (user_check_type(node, CDataSectionNode)) {\n            acc.push(\"<![CDATA[\");\n            // TODO: is this correct escaping???\n            acc.push(escape_value(node.cdata()));\n            acc.push(\"]]>\");\n        } else if (user_check_type(node, EntityReferenceNode)) {\n            acc.push(escape_value(node.entity_reference()));\n        } else if (user_check_type(node, ProcessingInstructionTargetNode)) {\n            acc.push(escape_value(node.processing_instruction_target()));\n        } else if (user_check_type(node, ProcessingInstructionDataNode)) {\n            acc.push(escape_value(node.string()));\n        } else if (user_check_type(node, TemplateInstanceNode)) {\n            throw new Error(\"UnexpectedElementException: TemplateInstanceNode\");\n        } else if (user_check_type(node, NormalSubstitutionNode)) {\n            var sub = subs[node.index()];\n            if (user_check_type(sub, BXmlTypeNode)) {\n                sub = render_root_node(sub.root());\n            } else {\n                sub = escape_value(sub.string());\n            }\n            acc.push(sub);\n        } else if (user_check_type(node, ConditionalSubstitutionNode)) {\n            var sub = subs[node.index()];\n            if (user_check_type(sub, BXmlTypeNode)) {\n                sub = render_root_node(sub.root());\n            } else {\n                sub = escape_value(sub.string());\n            }\n            acc.push(sub);\n        } else if (user_check_type(node, StreamStartNode)) {\n            // intended\n        }\n",
    "296": "var acc = [];\n    root_node.template().children().forEach(function(c) {\n        rec(c, acc);\n    });\n    return acc.join(\"\");\n",
    "297": "var subs = [];\n    for (var sub of root_node.substitutions()) {\n        if (user_check_type(sub, \"string\")) {\n            throw new RuntimeError(\"string sub?\");\n        }\n        if (sub === null) {\n            throw new RuntimeError(\"null sub?\");\n        }\n        subs.push(sub);\n    }\n    return render_root_node_with_subs(root_node, subs);\n",
    "298": "return render_root_node(record.root());\n",
    "299": "\n",
    "300": "\n",
    "301": "\n",
    "302": "\n",
    "303": "\n",
    "304": "\n",
    "305": "\n",
    "306": "\n",
    "307": "\n",
    "308": "\n",
    "309": "\n",
    "310": "\n",
    "311": "\n",
    "312": "\n",
    "313": "class_var.declare_field(\"string\", \"magic\", 0x0, 8);\nclass_var.declare_field(\"qword\", \"oldest_chunk\", null, null);\nclass_var.declare_field(\"qword\", \"current_chunk_number\", null, null);\nclass_var.declare_field(\"qword\", \"next_record_number\", null, null);\nclass_var.declare_field(\"dword\", \"header_size\", null, null);\nclass_var.declare_field(\"word\", \"minor_version\", null, null);\nclass_var.declare_field(\"word\", \"major_version\", null, null);\nclass_var.declare_field(\"word\", \"header_chunk_size\", null, null);\nclass_var.declare_field(\"word\", \"chunk_count\", null, null);\nclass_var.declare_field(\"binary\", \"unused1\", null, 0x4C);\nclass_var.declare_field(\"dword\", \"flags\", null, null);\nclass_var.declare_field(\"dword\", \"checksum\", null, null);\n",
    "314": "\n",
    "315": "\n",
    "316": "\n",
    "317": "var buffer = class_var.unpack_binary(0, 0x78);\nvar crc32 = require('crc-32');\nreturn crc32.buf(buffer) >>> 0;\n",
    "318": "\n",
    "319": "return (class_var.flags() & 0x1) === 0x1;\n",
    "320": "return (class_var.flags() & 0x2) === 0x2;\n",
    "321": "\n",
    "322": "\n",
    "323": "        if (include_inactive) {\n            chunk_count = 1000000;\n        } else {\n            chunk_count = class_var[\"chunk_count\"]();\n        }\n    \n        var i = 0;\n        var ofs = class_var[\"_offset\"] + class_var[\"header_chunk_size\"]();\n        while (ofs + 0x10000 <= class_var[\"_buf\"].length && i < chunk_count) {\n            _yield_value = new ChunkHeader(class_var[\"_buf\"], ofs);\n            yield _yield_value;\n            ofs += 0x10000;\n            i += 1;\n        }\n",
    "324": "\n",
    "325": "\n",
    "326": "\n",
    "327": "\n",
    "328": "\n",
    "329": "class_var._strings = null;\nclass_var._templates = null;\nclass_var.declare_field(\"string\", \"magic\", 0x0, 8);\nclass_var.declare_field(\"qword\", \"file_first_record_number\", null, null);\nclass_var.declare_field(\"qword\", \"file_last_record_number\", null, null);\nclass_var.declare_field(\"qword\", \"log_first_record_number\", null, null);\nclass_var.declare_field(\"qword\", \"log_last_record_number\", null, null);\nclass_var.declare_field(\"dword\", \"header_size\", null, null);\nclass_var.declare_field(\"dword\", \"last_record_offset\", null, null);\nclass_var.declare_field(\"dword\", \"next_record_offset\", null, null);\nclass_var.declare_field(\"dword\", \"data_checksum\", null, null);\nclass_var.declare_field(\"binary\", \"unused\", null, 0x44);\nclass_var.declare_field(\"dword\", \"header_checksum\", null, null);\n",
    "330": "\n",
    "331": "\n",
    "332": "return class_var.magic() === \"ElfChnk\\x00\";\n",
    "333": "var data = Buffer.concat([\n    class_var.unpack_binary(0x0, 0x78),\n    class_var.unpack_binary(0x80, 0x180)\n]);\nvar crc32 = require('crc-32');\nreturn crc32.buf(data) >>> 0;\n",
    "334": "var data = class_var.unpack_binary(0x200, class_var.next_record_offset() - 0x200);\nvar crc32 = require('crc-32');\nreturn crc32.buf(data) >>> 0;\n",
    "335": "\n",
    "336": "if (class_var._strings === null) {\n    class_var._strings = {};\n}\nfor (var i = 0; i < 64; i++) {\n    var ofs = class_var.unpack_dword(0x80 + (i * 4));\n    while (ofs > 0) {\n        var string_node = class_var.add_string(ofs, null);\n        ofs = string_node.next_offset();\n    }\n}\n",
    "337": "if (!class_var._strings) {\n    class_var._load_strings();\n}\nreturn class_var._strings;\n",
    "338": "if (class_var._strings === null) {\n    class_var._load_strings();\n}\nvar string_node = new NameStringNode(class_var._buf, class_var._offset + offset, class_var, parent || class_var);\nclass_var._strings[offset] = string_node;\nreturn string_node;\n",
    "339": "if (class_var._templates === null) {\n    class_var._templates = {};\n}\nfor (var i = 0; i < 32; i++) {\n    var ofs = class_var.unpack_dword(0x180 + (i * 4));\n    while (ofs > 0) {\n        var token = class_var.unpack_byte(ofs - 10);\n        var pointer = class_var.unpack_dword(ofs - 4);\n        if (token !== 0x0C || pointer !== ofs) {\n            ofs = 0;\n            continue;\n        }\n        var template = class_var.add_template(ofs, null);\n        ofs = template.next_offset();\n    }\n}\n",
    "340": "if (class_var._templates === null) {\n    class_var._load_templates();\n}\nvar node = new TemplateNode(class_var._buf, class_var._offset + offset, class_var, parent || class_var);\nclass_var._templates[offset] = node;\nreturn node;\n",
    "341": "if (!class_var._templates) {\n    class_var._load_templates();\n}\nreturn class_var._templates;\n",
    "342": "return new Record(class_var._buf, class_var._offset + 0x200, class_var);\n",
    "343": "try {\n    var record = class_var.first_record();\n} catch (e) {\n    if (e instanceof InvalidRecordException) {\n        return;\n    }\n}\nwhile (record._offset < class_var._offset + class_var.next_record_offset() && record.length() > 0) {\n    yield record;\n    try {\n        record = new Record(class_var._buf, record._offset + record.length(), class_var);\n    } catch (e) {\n        if (e instanceof InvalidRecordException) {\n            return null;\n        }\n    }\n}\n",
    "344": "class_var._chunk = chunk;\nclass_var.declare_field(\"dword\", \"magic\", 0x0, null);\n// 0x00002a2a\nclass_var.declare_field(\"dword\", \"size\", null, null);\nclass_var.declare_field(\"qword\", \"record_num\", null, null);\nclass_var.declare_field(\"filetime\", \"timestamp\", null, null);\nif (class_var.size() > 0x10000) {\n    return null;\n}\nclass_var.declare_field(\"dword\", \"size2\", class_var.size() - 4, null);\n",
    "345": "\n",
    "346": "\n",
    "347": "return new RootNode(class_var._buf, class_var._offset + 0x18, class_var._chunk, class_var);\n",
    "348": "    return class_var.size();\n",
    "349": "\n",
    "350": "\n",
    "351": "return evtx_record_xml_view(class_var, null);\n",
    "352": "var fh = new FileHeader(input_str, 0x0);\n    // collected empirically\n    var expecteds = tool_functions.expected_output1;\n    var tmp_gen = fh[\"chunks\"](false);\n\n    var i = 0;\n\n    while(true){\n        var x = (tmp_gen).next();\n        if (x.done) break\n        var chunk = x.value;\n\n        if (i < 9) {\n            console.assert(chunk[\"check_magic\"]() === true);\n            console.assert(chunk[\"magic\"]() === \"ElfChnk\\x00\");\n            console.assert(chunk[\"calculate_header_checksum\"]() === chunk[\"header_checksum\"]());\n            console.assert(chunk[\"calculate_data_checksum\"]() === chunk[\"data_checksum\"]());\n            var expected = expecteds[i];\n            console.assert(chunk[\"file_first_record_number\"]() === expected[\"start_file\"]);\n            console.assert(chunk[\"file_last_record_number\"]() === expected[\"end_file\"]);\n            console.assert(chunk[\"log_first_record_number\"]() === expected[\"start_log\"]);\n            console.assert(chunk[\"log_last_record_number\"]() === expected[\"end_log\"]);\n        } else {\n            console.assert(chunk[\"check_magic\"]() === false);\n            console.assert(chunk[\"magic\"]() === EMPTY_MAGIC);\n        }\n        i++;\n    }\n",
    "353": "    var fh = new FileHeader(input_str, 0x0);\n    // collected empirically\n    var expecteds = tool_functions.expected_output2;\n    var tmp_gen = fh[\"chunks\"](false);\n\n    var i = 0;\n\n    while(true){\n        var x = (tmp_gen).next();\n        if (x.done) break\n        var chunk = x.value;\n        if (i < 26) {\n            console.assert(chunk[\"check_magic\"]() === true);\n            console.assert(chunk[\"magic\"]() === \"ElfChnk\\x00\");\n            console.assert(chunk[\"calculate_header_checksum\"]() === chunk[\"header_checksum\"]());\n            console.assert(chunk[\"calculate_data_checksum\"]() === chunk[\"data_checksum\"]());\n\n            var expected = expecteds[i];\n            console.assert(chunk[\"file_first_record_number\"]() === expected[\"start_file\"]);\n            console.assert(chunk[\"file_last_record_number\"]() === expected[\"end_file\"]);\n            console.assert(chunk[\"log_first_record_number\"]() === expected[\"start_log\"]);\n            console.assert(chunk[\"log_last_record_number\"]() === expected[\"end_log\"]);\n\n        } else {\n            console.assert(chunk[\"check_magic\"]() === false);\n            console.assert(chunk[\"magic\"]() === EMPTY_MAGIC);\n        }\n        i++;\n    }\n",
    "354": "var fh = new FileHeader(input_str, 0x0);\n\n    // collected empirically\n    console.assert(fh[\"magic\"]() === \"ElfFile\\x00\");\n    console.assert(fh[\"major_version\"]() === 0x3);\n    console.assert(fh[\"minor_version\"]() === 0x1);\n    console.assert(fh[\"flags\"]() === 0x1);\n    console.assert(fh[\"is_dirty\"]() === true);\n    console.assert(fh[\"is_full\"]() === false);\n    console.assert(fh[\"current_chunk_number\"]() === 0x8);\n    console.assert(fh[\"chunk_count\"]() === 0x9);\n    console.assert(fh[\"oldest_chunk\"]() === 0x0);\n    console.assert(fh[\"next_record_number\"]() === 0x34D8);\n    console.assert(fh[\"checksum\"]() === 0x41B4B1EC);\n    console.assert(fh[\"calculate_checksum\"]() === fh[\"checksum\"]());\n",
    "355": "var fh = new FileHeader(input_str, 0x0);\n\n    // collected empirically\n    console.assert(fh[\"magic\"]() === \"ElfFile\\x00\");\n    console.assert(fh[\"major_version\"]() === 0x3);\n    console.assert(fh[\"minor_version\"]() === 0x1);\n    console.assert(fh[\"flags\"]() === 0x1);\n    console.assert(fh[\"is_dirty\"]() === true);\n    console.assert(fh[\"is_full\"]() === false);\n    console.assert(fh[\"current_chunk_number\"]() === 0x19);\n    console.assert(fh[\"chunk_count\"]() === 0x1A);\n    console.assert(fh[\"oldest_chunk\"]() === 0x0);\n    console.assert(fh[\"next_record_number\"]() === 0x8B2);\n    console.assert(fh[\"checksum\"]() === 0x3F6E33D5);\n    console.assert(fh[\"calculate_checksum\"]() === fh[\"checksum\"]());\n",
    "356": "\n",
    "357": "var name = node['_class_name'].split(\";\")[0];\n    var value = null;\n\n    if (user_check_type(node, BXmlTypeNode)) {\n        // must go before is VariantTypeNode\n        value = null;\n    } else if (user_check_type(node, VariantTypeNode)) {\n        value = node[\"string\"]();\n    } else if (user_check_type(node, OpenStartElementNode)) {\n        value = node[\"tag_name\"]();\n    } else if (user_check_type(node, AttributeNode)) {\n        value = node[\"attribute_name\"]()[\"string\"]();\n    } else {\n        value = null;\n    }\n\n    var children = [];\n    if (user_check_type(node, BXmlTypeNode)) {\n        children.push(extract_structure(node[\"_root\"]));\n    } else if (user_check_type(node, TemplateInstanceNode) && node[\"is_resident_template\"]()) {\n        children.push(extract_structure(node[\"template\"]()));\n    }\n\n    children = children.concat(Array.from(node[\"children\"]()).map(child => extract_structure(child)));\n\n    if (user_check_type(node, RootNode)) {\n        var substitutions = Array.from(node[\"substitutions\"]()).map(substitution => extract_structure(substitution));\n        children.push([\"Substitutions\", null, substitutions]);\n    }\n\n    var _return_value;\n    if (children.length > 0) {\n        _return_value = [name, value, children];\n    } else if (value !== null) {\n        _return_value = [name, value];\n    } else {\n        _return_value = [name];\n    }\n    return _return_value;\n",
    "358": "var fh = new FileHeader(input_str, 0x0);\n    var chunk = fh[\"chunks\"](false).next().value;\n    var record = chunk[\"records\"]().next().value;\n\n    var expected = tool_functions.expected_output3;\n    if (JSON.stringify(extract_structure(record['root']())) !== JSON.stringify(expected)) {\n        throw new Error(\"Assertion failed\");\n    }\n",
    "359": "var fh = new FileHeader(input_str, 0x0);\n\n    var chunk = fh[\"chunks\"](false).next().value;\n    var record = chunk[\"records\"]().next().value;\n\n    var xml = record[\"xml\"]();\n    if (JSON.stringify(xml) !== JSON.stringify(tool_functions.expected_output4)) {\n        throw new Error(\"Assertion failed\");\n    }\n",
    "360": "var fh = new FileHeader(input_str, 0x0);\n    var tmp_gen = fh[\"chunks\"](false);\n    while(true){\n        var x = (tmp_gen).next();\n        if (x.done) break\n        var chunk = x.value;\n        var tmp_gen2 = chunk[\"records\"]();\n        while(true){\n            var y = (tmp_gen2).next();\n            if (y.done) break\n            var record = y.value;\n            if (record[\"magic\"]() !== 0x2A2A) {\n                throw new Error(\"Assertion failed\");\n            }\n        }\n    }\n",
    "361": "var fh = new FileHeader(input_str, 0x0);\n    var tmp_gen = fh[\"chunks\"](false);\n    while(true){\n        var x = (tmp_gen).next();\n        if (x.done) break\n        var chunk = x.value;\n        var tmp_gen2 = chunk[\"records\"]();\n        while(true){\n            var y = (tmp_gen2).next();\n            if (y.done) break\n            var record = y.value;\n            if (record[\"magic\"]() !== 0x2A2A) {\n                throw new Error(\"Assertion failed\");\n            }\n        }\n    }\n",
    "362": "    var fh = new FileHeader(input_str, 0x0);\n    var tmp_gen = fh[\"chunks\"](false);\n    while(true){\n        var x = (tmp_gen).next();\n        if (x.done) break\n        var chunk = x.value;\n        var tmp_gen2 = chunk[\"records\"]();\n        while(true){\n            var y = (tmp_gen2).next();\n            if (y.done) break\n            var record = y.value;\n            var xml = record[\"xml\"]();\n            if (xml == null) {\n                throw new Error(\"Assertion failed\");\n            }\n        }\n    }\n",
    "363": "var fh = new FileHeader(input_str, 0x0);\n    var tmp_gen = fh[\"chunks\"](false);\n    // var ct = 0\n    while(true){\n        var x = (tmp_gen).next();\n        if (x.done) break\n        var chunk = x.value;\n        var tmp_gen2 = chunk[\"records\"]();\n        while(true){\n            var y = (tmp_gen2).next();\n            if (y.done) break\n            var record = y.value;\n            var xml = record[\"xml\"]();\n            if (xml == null) {\n                throw new Error(\"Assertion failed\");\n            }\n        }\n    }\n",
    "364": "\n",
    "365": "\n",
    "366": "\n",
    "367": "\n",
    "368": "    test_render_records2(tool_functions.get_input(\"case2\"))\n    console.log(\"All tests passed\")\n",
    "0": "\n\nEMPTY_MAGIC = \"\\x00\" * 0x8\n\nXML_HEADER = '<?xml version=\"1.1\" encoding=\"utf-8\" standalone=\"yes\" ?>\\n'\n\nNODE_TYPES = {\n    \"NULL\": 0x00,\n    \"WSTRING\": 0x01,\n    \"STRING\": 0x02,\n    \"SIGNED_BYTE\": 0x03,\n    \"UNSIGNED_BYTE\": 0x04,\n    \"SIGNED_WORD\": 0x05,\n    \"UNSIGNED_WORD\": 0x06,\n    \"SIGNED_DWORD\": 0x07,\n    \"UNSIGNED_DWORD\": 0x08,\n    \"SIGNED_QWORD\": 0x09,\n    \"UNSIGNED_QWORD\": 0x0A,\n    \"FLOAT\": 0x0B,\n    \"DOUBLE\": 0x0C,\n    \"BOOLEAN\": 0x0D,\n    \"BINARY\": 0x0E,\n    \"GUID\": 0x0F,\n    \"SIZE\": 0x10,\n    \"FILETIME\": 0x11,\n    \"SYSTEMTIME\": 0x12,\n    \"SID\": 0x13,\n    \"HEX32\": 0x14,\n    \"HEX64\": 0x15,\n    \"BXML\": 0x21,\n    \"WSTRINGARRAY\": 0x81\n}\n\nSYSTEM_TOKENS = {\n    \"EndOfStreamToken\": 0x00,\n    \"OpenStartElementToken\": 0x01,\n    \"CloseStartElementToken\": 0x02,\n    \"CloseEmptyElementToken\": 0x03,\n    \"CloseElementToken\": 0x04,\n    \"ValueToken\": 0x05,\n    \"AttributeToken\": 0x06,\n    \"CDataSectionToken\": 0x07,\n    \"EntityReferenceToken\": 0x08,\n    \"ProcessingInstructionTargetToken\": 0x0A,\n    \"ProcessingInstructionDataToken\": 0x0B,\n    \"TemplateInstanceToken\": 0x0C,\n    \"NormalSubstitutionToken\": 0x0D,\n    \"ConditionalSubstitutionToken\": 0x0E,\n    \"StartOfStreamToken\": 0x0F\n}\n\nnode_types_dict = {\n        0x00: NullTypeNode,\n        0x01: WstringTypeNode,\n        0x02: StringTypeNode,\n        0x03: SignedByteTypeNode,\n        0x04: UnsignedByteTypeNode,\n        0x05: SignedWordTypeNode,\n        0x06: UnsignedWordTypeNode,\n        0x07: SignedDwordTypeNode,\n        0x08: UnsignedDwordTypeNode,\n        0x09: SignedQwordTypeNode,\n        0x0A: UnsignedQwordTypeNode,\n        0x0B: FloatTypeNode,\n        0x0C: DoubleTypeNode,\n        0x0D: BooleanTypeNode,\n        0x0E: BinaryTypeNode,\n        0x0F: GuidTypeNode,\n        0x10: SizeTypeNode,\n        0x11: FiletimeTypeNode,\n        0x12: SystemtimeTypeNode,\n        0x13: SIDTypeNode,\n        0x14: Hex32TypeNode,\n        0x15: Hex64TypeNode,\n        0x21: BXmlTypeNode,\n        0x81: WstringArrayTypeNode,\n}\n\nnode_dispatch_table = [\n    EndOfStreamNode,\n    OpenStartElementNode,\n    CloseStartElementNode,\n    CloseEmptyElementNode,\n    CloseElementNode,\n    ValueNode,\n    AttributeNode,\n    CDataSectionNode,\n    CharacterReferenceNode,\n    EntityReferenceNode,\n    ProcessingInstructionTargetNode,\n    ProcessingInstructionDataNode,\n    TemplateInstanceNode,\n    NormalSubstitutionNode,\n    ConditionalSubstitutionNode,\n    StreamStartNode,\n]\n\ntest()\n"
}